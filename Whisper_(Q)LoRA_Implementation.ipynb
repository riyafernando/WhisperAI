{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riyafernando/WhisperAI/blob/main/Whisper_(Q)LoRA_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntcmFFCbjFr9",
        "outputId": "a84c72d4-c5ad-49a0-a06a-59577f118155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q bitsandbytes datasets accelerate loralib\n",
        "!pip install -q git+https://github.com/huggingface/peft.git git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKHg0OasjQR1",
        "outputId": "09f7c3e2-c00a-4ded-fb2d-35d66aed63e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "f0c33d5b475240489b54d1d632eda310",
            "ebeac2b281924e76816a413137fb4829",
            "1e7eb8061117437dae20294b6a339e84",
            "3d437871d0da4140ae274be40c599a10",
            "37ab5bcff66e4fdba81d12ea26dbab89",
            "7e571eac518d499183c0f3805101cb3d"
          ]
        },
        "id": "HoC6TVjsj24r",
        "outputId": "e44ee49e-49af-4101-e26d-4b0719ad57c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0c33d5b475240489b54d1d632eda310",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebeac2b281924e76816a413137fb4829",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of WhisperForConditionalGeneration were not initialized from the model checkpoint at openai/whisper-small and are newly initialized: ['proj_out.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e7eb8061117437dae20294b6a339e84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/3.51k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d437871d0da4140ae274be40c599a10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/227 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37ab5bcff66e4fdba81d12ea26dbab89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e571eac518d499183c0f3805101cb3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import bitsandbytes as bnb\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        pretrained_model_name_or_path=\"openai/whisper-small\",\n",
        "        load_in_4bit=True,\n",
        "        device_map='auto',\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7b-fy1fhkugi",
        "outputId": "3f544f4d-f5d4-4ac2-feba-33ab5769e091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WhisperForConditionalGeneration(\n",
            "  (model): WhisperModel(\n",
            "    (encoder): WhisperEncoder(\n",
            "      (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "      (embed_positions): Embedding(1500, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0-11): 12 x WhisperEncoderLayer(\n",
            "          (self_attn): WhisperAttention(\n",
            "            (k_proj): Linear4bit(in_features=768, out_features=768, bias=False)\n",
            "            (v_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): WhisperDecoder(\n",
            "      (embed_tokens): Embedding(51865, 768, padding_idx=50257)\n",
            "      (embed_positions): WhisperPositionalEmbedding(448, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0-11): 12 x WhisperDecoderLayer(\n",
            "          (self_attn): WhisperAttention(\n",
            "            (k_proj): Linear4bit(in_features=768, out_features=768, bias=False)\n",
            "            (v_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): WhisperAttention(\n",
            "            (k_proj): Linear4bit(in_features=768, out_features=768, bias=False)\n",
            "            (v_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (proj_out): Linear(in_features=768, out_features=51865, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#need to choose which weight matrices to decompose (in paper, query + value)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ubTdpJjQm17Z"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hsp23N65lL77",
        "outputId": "d6f3c710-5ff4-4f71-bdd1-4a21856f8b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 884736 || all params: 143529216 || trainable%: 0.6164152669795117\n"
          ]
        }
      ],
      "source": [
        "#target v_proj and q_proj\n",
        "from peft import LoraConfig, get_peft_model\n",
        "#set rank / number of dimensions\n",
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=8, #origionally 16\n",
        "    target_modules=[\"v_proj\", \"q_proj\"], #just doing query + values\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"LARGE_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjXkW_QOnnqM"
      },
      "source": [
        "Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nShBtlhkw_p"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWfyfd8Nn5sC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\", load_in_4bit=True, device_map=\"auto\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbxCmGQn5urGggs2mxieOE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}